{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f6a0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <CDAC6E34-8608-3E70-8B2F-32BCD38E90FB> /opt/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.data.data_loader import create_dataloaders\n",
    "from src.model.transformer import build_transformer\n",
    "from src.model.transformer import Transformer\n",
    "from src.train.training import train_model\n",
    "from src.utils.utils import get_device\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from src.utils.constants import PADDING, UNKNOWN, START_OF_SENTENCE, END_OF_SENTENCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f481b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and training parameters\n",
    "\n",
    "# Size of embedding vector\n",
    "d_model = 512\n",
    "# Max sequence length for input words/tokens\n",
    "seq_len = 100\n",
    "# Dropout rate\n",
    "dropout = 0.1\n",
    "# number of encoder blocks\n",
    "num_layers = 1\n",
    "# number of attention heads\n",
    "num_heads = 8\n",
    "# Number of hidden nodes for feed-forward layer\n",
    "d_ff = 4*d_model\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 5\n",
    "# Batch size for training\n",
    "batch_size = 128\n",
    "\n",
    "# Train file\n",
    "train_file = './data/train/poems.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c639278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokenized words:  194655\n",
      "Number of tokenized words after adding <eos>:  194755\n",
      "Training data size: 194688\n"
     ]
    }
   ],
   "source": [
    "# Get a device to use for training/inference\n",
    "device = get_device()\n",
    "\n",
    "# Create training and testing data loaders\n",
    "train_dataloader, vocab = create_dataloaders(batch_size, seq_len, train_file)\n",
    "\n",
    "print(f'Training data size: {len(train_dataloader) * batch_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6517f3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (embed): InputEmbedding(\n",
      "    (embedding): Embedding(6993, 512)\n",
      "  )\n",
      "  (pos): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): EncoderBlock(\n",
      "        (self_attention): MultiHeadAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (query_linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (key_linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (value_linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
      "          (output_linear_layer): Linear(in_features=512, out_features=512, bias=True)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (linear_1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (projection_layer): ProjectionLayer(\n",
      "    (linear_layer): Linear(in_features=512, out_features=6993, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create encoder only transformer model\n",
    "encoder_only_transformer_model = build_transformer(d_model, len(vocab), seq_len, dropout,\n",
    "                                                   num_layers, num_heads, d_ff).to(device)\n",
    "\n",
    "print(encoder_only_transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "899fd3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss 0.8270629644393921\n",
      "Epoch 2, Train Loss 0.23350630700588226\n",
      "Epoch 3, Train Loss 0.20912890136241913\n",
      "Epoch 4, Train Loss 0.19805137813091278\n",
      "Epoch 5, Train Loss 0.19233782589435577\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "\n",
    "# Create optimizer and loss function\n",
    "optimizer = torch.optim.Adam(encoder_only_transformer_model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Start training the model\n",
    "train_model(epochs, encoder_only_transformer_model, train_dataloader,\n",
    "            loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67491617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "from pathlib import Path\n",
    "\n",
    "# Create models directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create model save path\n",
    "MODEL_NAME = \"07_text_generation.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55bd5a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models/07_text_generation.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=encoder_only_transformer_model.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba8bc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new instance of model and load saved state dict\n",
    "loaded_model = build_transformer(d_model, len(vocab), seq_len, dropout,\n",
    "                                num_layers, num_heads, d_ff)\n",
    "loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "loaded_model.to(device)\n",
    "\n",
    "UNK = 1\n",
    "\n",
    "def generate_text(input, max_tokens_to_generate):\n",
    "    with torch.inference_mode():\n",
    "        \n",
    "        output = input.clone()\n",
    "        for _ in range(max_tokens_to_generate):\n",
    "            \n",
    "            curr_seq_len = input.size(1)\n",
    "            \n",
    "            if curr_seq_len > seq_len:\n",
    "                input = input[:, -seq_len:]\n",
    "            \n",
    "            encoder_output = loaded_model.encode(input)\n",
    "            y_logits = loaded_model.project(encoder_output)\n",
    "            \n",
    "            # for all the batches, get the embeds for last predicted sequence\n",
    "            y_logits = y_logits[:, -1, :] \n",
    "            \n",
    "            # for all the batches, get the embeds for last predicted sequence\n",
    "            probs = y_logits.softmax(dim=1)            \n",
    "            # get the probable token based on the input probs\n",
    "            idx_next = torch.multinomial(probs, num_samples=1) \n",
    "\n",
    "            input = torch.cat([input, idx_next], dim=1)\n",
    "            output = torch.cat([output, idx_next], dim=1)\n",
    "            \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a960e2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Love the way you conquer your fear , You know hearts do n't break around here , Oh yeah , yeah , Yeah-yeah , yeah-yeah She is the river flowin ' nowhere , And tin wind chimes used for doorbells , Fields and trees and her smell fill my lungs , Spend my summertime beside her , And the rest of the year the same , She is the flint that sparks the lighter , And the fuel that will hold the flame , oh Roses , roses laid upon your bed spread , oh my , All this , all this , all this I know But every night I 'll kiss you , you 'll say in my ear , Oh we 're in love , are n't we ? Hands in your hair Fingers and thumbs , baby I feel safe when you 're holding me near , Love the way that you conquer your fear , You know hearts do n't break around here , Oh yeah , yeah , yeah , yeah , Yeah-yeah , yeah-yeah Well , I 've found love inside , The arms of the river flowin ' nowhere And tin wind chimes\n"
     ]
    }
   ],
   "source": [
    "text = 'Love'\n",
    "input = [vocab.get(token, UNKNOWN) for token in word_tokenize(text)]\n",
    "input_tensor = torch.tensor(input, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "output_tensor = generate_text(input_tensor, 200).squeeze()\n",
    "output_array_tokens = output_tensor.cpu().numpy()\n",
    "\n",
    "sorted_items = sorted(vocab.items(), key=lambda item: item[1])\n",
    "sorted_keys = [item[0] for item in sorted_items]\n",
    "\n",
    "output_array_words = [sorted_keys[token] for token in output_array_tokens]\n",
    "print(' '.join(output_array_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9df3d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conquer , You know maybe These people that hate me But you , I knew you were n't around here And you wanted to make me and it 's real , When we watched the sunset over the castle on the hill , Over the castle on the hill , Over the castle on the hill '' When I was six years old , I broke my leg , I was running from my brother and his friends , And tasted the sweet perfume of the mountain grass I rolled down , I was younger then , Take me back that you said , take me back now Now we got down , `` I 'll never ring '' He 's in the rain '' He said , `` no do n't get '' Have ever known That 's been and I would 've never leave me I thought , Back when we had you figured out Something 's We were the nerve To touch my hand It 's nice to have to have a friend ( Ooh ) It was so nice being midnight It 's nice to leave It 's stayed true I kind of knew you He 's\n"
     ]
    }
   ],
   "source": [
    "text = 'conquer'\n",
    "input = [vocab.get(token, UNKNOWN) for token in word_tokenize(text)]\n",
    "input_tensor = torch.tensor(input, dtype=torch.long).unsqueeze(0).to(device)\n",
    "\n",
    "output_tensor = generate_text(input_tensor, 200).squeeze()\n",
    "output_array_tokens = output_tensor.cpu().numpy()\n",
    "\n",
    "sorted_items = sorted(vocab.items(), key=lambda item: item[1])\n",
    "sorted_keys = [item[0] for item in sorted_items]\n",
    "\n",
    "output_array_words = [sorted_keys[token] for token in output_array_tokens]\n",
    "print(' '.join(output_array_words))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
