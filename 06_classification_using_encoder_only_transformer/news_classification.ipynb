{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9aa4c8c0",
   "metadata": {},
   "source": [
    "<h1><center>AG News Classification</center></h1>\n",
    "\n",
    "AG is a collection of more than 1 million news articles. News articles have been gathered from more than 2000 news sources by ComeToMyHead in more than 1 year of activity. ComeToMyHead is an academic news search engine which has been running since July, 2004. The dataset is provided by the academic comunity for research purposes in data mining (clustering, classification, etc), information retrieval (ranking, search, etc), xml, data compression, data streaming, and any other non-commercial activity.\n",
    "\n",
    "The AG's news topic classification dataset is constructed by choosing 4 largest classes from the original corpus. Each class contains 30,000 training samples and 1,900 testing samples. The total number of training samples is 120,000 and testing 7,600."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "85f6a0b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/opt/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <CFED5F8E-EC3F-36FD-AAA3-2C6C7F8D3DD9> /opt/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <CDAC6E34-8608-3E70-8B2F-32BCD38E90FB> /opt/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from src.data.data_loader import create_dataloaders\n",
    "from src.model.transformer import build_transformer\n",
    "from src.model.transformer import Transformer\n",
    "from src.train.training import train_model\n",
    "from src.utils.utils import get_device\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f481b650",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model and training parameters\n",
    "\n",
    "train_file = 'data/train/train.csv'\n",
    "val_file = 'data/val/val.csv'\n",
    "\n",
    "# Size of embedding vector\n",
    "d_model = 64\n",
    "# Number of words in a vocabulary\n",
    "vocab_size = 30000\n",
    "# Max sequence length for input words/tokens\n",
    "seq_len = 100\n",
    "# Dropout rate\n",
    "dropout = 0.1\n",
    "# number of encoder blocks\n",
    "num_layers = 1\n",
    "# number of attention heads\n",
    "num_heads = 8\n",
    "# Number of hidden nodes for feed-forward layer\n",
    "d_ff = 4*64\n",
    "\n",
    "# Number of epochs\n",
    "epochs = 5\n",
    "# Batch size for training\n",
    "batch_size = 128\n",
    "# Number of classes\n",
    "num_classes = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1c639278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get a device to use for training/inference\n",
    "device = get_device()\n",
    "\n",
    "# Create training and validation data loaders\n",
    "train_dataloader, val_dataloader, word_to_id = create_dataloaders(train_file, val_file, batch_size, seq_len,\n",
    "                                                                   vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6517f3f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformer(\n",
      "  (embed): InputEmbedding(\n",
      "    (embedding): Embedding(30000, 64)\n",
      "  )\n",
      "  (pos): PositionalEncoding(\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (encoder): Encoder(\n",
      "    (layers): ModuleList(\n",
      "      (0): EncoderBlock(\n",
      "        (self_attention): MultiHeadAttention(\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (query_linear_layer): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (key_linear_layer): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (value_linear_layer): Linear(in_features=64, out_features=64, bias=True)\n",
      "          (output_linear_layer): Linear(in_features=64, out_features=64, bias=True)\n",
      "        )\n",
      "        (feed_forward): FeedForward(\n",
      "          (linear_1): Linear(in_features=64, out_features=256, bias=True)\n",
      "          (dropout): Dropout(p=0.1, inplace=False)\n",
      "          (linear_2): Linear(in_features=256, out_features=64, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.1, inplace=False)\n",
      "        (norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (projection_layer): ProjectionLayer(\n",
      "    (linear_layer): Linear(in_features=64, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Create encoder only transformer model\n",
    "encoder_only_transformer_model = build_transformer(d_model, vocab_size, seq_len, dropout,\n",
    "                                                   num_layers, num_heads, d_ff, num_classes).to(device)\n",
    "\n",
    "print(encoder_only_transformer_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "899fd3de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss 0.32070717215538025, Train Accuracy 0.884453296661377, Test Loss 0.23113450407981873, Test Accuracy 0.9214843511581421\n",
      "Epoch 2, Train Loss 0.15500973165035248, Train Accuracy 0.9456123113632202, Test Loss 0.23425127565860748, Test Accuracy 0.9262152910232544\n",
      "Epoch 3, Train Loss 0.10607817769050598, Train Accuracy 0.9610374569892883, Test Loss 0.2572510540485382, Test Accuracy 0.9264323115348816\n",
      "Epoch 4, Train Loss 0.07226314395666122, Train Accuracy 0.9725063443183899, Test Loss 0.3279348909854889, Test Accuracy 0.917881965637207\n",
      "Epoch 5, Train Loss 0.05304388329386711, Train Accuracy 0.9799773693084717, Test Loss 0.3840404152870178, Test Accuracy 0.9115017652511597\n"
     ]
    }
   ],
   "source": [
    "# Create optimizer and loss function\n",
    "optimizer = torch.optim.Adam(encoder_only_transformer_model.parameters())\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "# Train model\n",
    "train_model(epochs, num_classes, encoder_only_transformer_model, train_dataloader, val_dataloader,\n",
    "            loss_fn, optimizer, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67491617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "from pathlib import Path\n",
    "\n",
    "# Create models directory\n",
    "MODEL_PATH = Path(\"models\")\n",
    "MODEL_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create model save path\n",
    "MODEL_NAME = \"06_news_classification.pth\"\n",
    "MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55bd5a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving model to: models/06_news_classification.pth\n"
     ]
    }
   ],
   "source": [
    "# Save the model state dict\n",
    "print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n",
    "torch.save(obj=encoder_only_transformer_model.state_dict(), f=MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ba8bc165",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new instance of model and load saved state dict\n",
    "loaded_model = build_transformer(d_model, vocab_size, seq_len, dropout,\n",
    "                                num_layers, num_heads, d_ff, num_classes)\n",
    "loaded_model.load_state_dict(torch.load(MODEL_SAVE_PATH))\n",
    "loaded_model.to(device)\n",
    "\n",
    "# Categories\n",
    "article_categories = {1: 'World', 2:'Sports', 3:'Business', 4:'Sci/Tech'}\n",
    "\n",
    "UNK = 1\n",
    "\n",
    "def classify_news(news):\n",
    "    with torch.inference_mode():\n",
    "        tokenized_words = word_tokenize(news.lower())[0: seq_len]\n",
    "        news_tensor = torch.tensor([word_to_id.get(word, UNK) for word in tokenized_words]).to(device)\n",
    "        \n",
    "        news_tensor = news_tensor.unsqueeze(dim=0)\n",
    "        \n",
    "        encoder_output = loaded_model.encode(news_tensor, None)\n",
    "        y_logits = loaded_model.project(encoder_output)\n",
    "        \n",
    "        y_output = torch.argmax(y_logits, dim=1)\n",
    "        return (y_output.item()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a960e2a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sports\n"
     ]
    }
   ],
   "source": [
    "article1 = 'The NBA season could end on Thursday night. Itâ€™s Game 6 of the NBA Finals, with the Oklahoma City Thunder leading the \\\n",
    "Indiana Pacers 3-2 in the title series. Game 6 is in Indianapolis and Game 7, if necessary, will be Sunday.Shai Gilgeous-Alexander and the \\\n",
    "Thunder are one win away from becoming NBA champions. And Gilgeous-Alexander is on the cusp of a nearly unprecedented season when it comes \\\n",
    "to individual honors.'\n",
    "\n",
    "print(article_categories.get(classify_news(article1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19d6409b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Business\n"
     ]
    }
   ],
   "source": [
    "article2 = 'Global stock markets are experiencing fluctuations due to changing economic indicators, \\\n",
    "central bank policies, and geopolitical developments.'\n",
    "\n",
    "print(article_categories.get(classify_news(article2)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
